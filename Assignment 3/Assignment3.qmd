---
title: "Assignment 3"
author: "David Gyaraki, Thao Le"
format: pdf
pdf:
  documentclass: article
  cite-method: biblatex
editor: visual
include-in-header:
  text: |
    \addtokomafont{disposition}{\rmfamily}
    \usepackage{amsmath}
    \newcommand{\bm}{\symbf}
    \newcommand{\T}{\text{T}}
    \newcommand{\pl}{\text{plim}}
    \newcommand{\brefsection}[1]{Section \textcolor{blue}{\ref{#1}}}
    \newcommand{\beqref}[1]{Equation \textcolor{blue}{\eqref{#1}}}
    \newcommand{\breftable}[1]{Table \textcolor{blue}{\ref{#1}}}
    \newcommand{\breffig}[1]{Figure \textcolor{blue}{\ref{#1}}}
    \usepackage{fancyvrb}
    \usepackage{dcolumn}
    \usepackage{fvextra}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaklines,
      commandchars=\\\{\}
    }
pdf-engine: xelatex
cap-location: top
toc: true
toc-title: Contents
number-sections: true
mainfont: Arial
setspace:
  linestretch: 1.25
fig-align: center
table-align: center
fig-pos: H
table-pos: H
execute:
  echo: true
  warning: false
  eval: true
code-line-numbers: false
colorlinks: true
code-block-bg: darkgray
df-print: default
highlight-style: arrow-dark
biblio-title: References
---

\clearpage

```{r setup q1, echo=TRUE, results='hide'}
# load packages
if(!require(pacman)){install.packages("pacman")}

p_load(devtools,tidyverse,dplyr,ggplot2,latex2exp,
       sampleSelection, quantreg, plm, nlme, knitr,car)
```

\section{Question 1}

\begin{table}[H] \centering
\begin{tabular}{l|cc|cc}
\hline
\hline
color  & \multicolumn{2}{c}{number of individual} & \multicolumn{2}{c}{average outcome} \\
       & treated             & control            & treated          & control          \\ \hline
purple & 100                 & 100                & 9                & 7                \\
blue   & 75                  & 25                 & 13               & 8                \\
green  & 25                  & 75                 & 10               & 9               \\
\hline
\hline
\end{tabular}
\end{table}

\subsection{(i)} \label{q1_1}

The treatment effect in theory is the difference between the outcomes if the individual is treated versus if the individual is not treated. Suppose that for individual $i$, the treatment effect is defined as:

\begin{equation}
TE_i = \Delta_i = y_{i,d=1} - y_{i,d=0},
\end{equation}

\noindent where the $y$ marks the outcome and $d$ is the dummy whether individual $i$ was treated ($d=1$) or not ($d=0$). However, this is rarely possible to be observed for each individual, as treatment is generally considered mutually exclusive, so an individual is either treated or not. Therefore, in this example we cannot calculate TE measures for individuals within color groups, but we can pretend as if one color corresponds to one observation, and calculate the three treatment effects across the color groups.

Then, the treatment effect for "observation" purple is $9 - 7 = 2$, the treatment effect for "observation" blue is $13 - 8 = 5$ and the treatment effect for "observation" green is $10 - 9 = 1$. 

\subsection{(ii)} \label{q1_2}

Using the assumption of \brefsection{q1_1}, we can infer here that we are looking for the average treatment effect of the full population including all colors. The average treatment effect is generally given by:

\begin{equation}
ATE = E[\Delta] = E[y_{d=1} - y_{d=0}],
\end{equation}

\noindent where we take the average across the observation differences. Our data in the exercise does not contain information again on the individual outcomes, however we can use the average outcomes of treatment and control in each color group to calculate the total differences between $y_{d=1}$ and $y_{d=0}$ on the full population. Therefore, we can calculate the ATE as:

```{r}
E_diff_purple = 9 - 7
E_diff_blue = 13 - 8 
E_diff_green = 10 - 9
  
ATE = (E_diff_purple * 200 + E_diff_blue * 100 + E_diff_green * 100) / 400
ATE
```

\subsection{(iii)} \label{q1_3}

Compared to the solution in \brefsection{q1_2}, now we consider the average treatment effect among treated (ATET). For this case, we need to modify the previous definition to:

\begin{equation}
\begin{aligned}
ATET & = E[\Delta | d=1] = E[y_{d=1} - y_{d=0} | d=1] = E[y_{d=1}] - E[y_{d=0}] 
\\
& = \frac{1}{N_T} \Sigma^{N_T}_{i=1} y_{i,d=1} - \frac{1}{N_{NT}} \Sigma^{N_{NT}}_{i=1} y_{i,d=0},
\end{aligned}
\end{equation}

\noindent where $N_T$ is the number of individuals in the treatment group while $N_{NT}$ is the number of individuals in the control group. Therefore, the ATET for the whole population can be calculated as:

```{r}
E_treatment_atet <- (9*100 + 13*75 + 10*25) / (100+75+25)
E_control_atet <- (7*100 + 8*25 + 9*75) / (100+75+25)

ATET = E_treatment_atet - E_control_atet
ATET
```

\subsection{(iv)} \label{q1_4}

The ATE measure generally describes the expected gain in $y$ achieved by treating a random member $i$ from the population, i.e. how much one benefits from being selected for the treatment compared to people who were not. On the other hand, ATET describes the average gain achieved by the treatment for the treated group, i.e. the comparison is not to the population but peer-to-peer, what is the expected benefit for those who are selected. The ATET is more helpful if we are not mainly interested in the potentially positive effect of the treatment for those who are treated versus those who are not, but rather the magnitude of these positive effects. Suppose that we have an experiment where the government announces a new plan to introduce an additional level of health insurance, where the own risk cost would be cut in half, in order to investigate the effects of these on household savings. Arguably, cutting the own risk cost in half without changing the insurance monthly premiums would most likely have a positive effect on the wealth for those who are involved in the initial study, but if the government is rather interested in measuring the average savings surplus this would create for households, we would be more interested in the ATET measure as this policy will ideally be introduced for everyone later on and we are solely interested in the average savings surplus this would create for everyone involved.

\section{Question 2}

```{r load data q2, echo=TRUE, results='hide'}
dfData = read.csv("bonus.csv")
attach(dfData)

dfData <- na.omit(dfData)
```

\subsection{(i)} \label{q2_1}

```{r}
df_noR <- dfData[dfData$bonus0 == 1,]
df_lowR <- dfData[dfData$bonus500 == 1,]
df_highR <- dfData[dfData$bonus1500 == 1,]

sum_noR <- sapply(df_noR, mean, na.rm=TRUE)
sum_lowR <- sapply(df_lowR, mean, na.rm=TRUE)
sum_highR <- sapply(df_highR, mean, na.rm=TRUE)

summary_table <- cbind(sum_noR, sum_lowR, sum_highR)

kable(summary_table, caption="The means of the predictor and dependent variables across the three groups", col.names = c("no reward", "low reward", "high reward"), digits = 3)
```

As we can see from the summary table above, the no reward group saw a 19.5\% pass rate, the low reward group saw a 20.2\% pass rate while the high reward group saw a 24.1\% pass rate. At the same time, we can also look at the other numeric variables to investigate their means and check how balanced the other predictors are. Naturally since we grouped the students based on the incentives, the three \textit{bonus} variables will not be balanced. However, the other ones are quite similar among the three groups implying that the background characteristics are relatively balanced. In particular, parental educational background (\textit{myeduc} and \textit{fyeduc}) and high-school math scores (\textit{math}) are quite similar to one another among groups.

\subsection{(ii)} \label{q2_2}

```{r}
prob_lm1 <- lm(pass ~ bonus500 + bonus1500, data = dfData)
prob_lm2 <- lm(pass ~ bonus500 + bonus1500 + fyeduc + p0 + math, data = dfData)
prob_lm3 <- lm(pass ~ bonus500 + bonus1500 + fyeduc + p0 + math +job +effort, data = dfData)
```

```{r, echo=TRUE, results='hide'}
stargazer::stargazer(prob_lm1,prob_lm2,prob_lm3, title="Estimating the effects of treatment on first year pass rate",  align=TRUE, label = "tab_pass", table.placement="H", out = "tab_pass.tex")
```

\input{tab_pass.tex}

In order to estimate a model with the 2 treatment and 1 control groups, we need to be careful about the model specification. We cannot simply add all three dummy variables as predictors in the model, since the three groups are mutually exclusive and exhaustive so adding all three dummies in the model would cause perfect multicollinearity. Hence we can only use 2 of the 3 variables and the combination of both variables being 0 gives the "third variable". Therefore, we only estimate a model with the two treatment group dummies.

Looking at the summary statistics for the first model in \breftable{tab_pass} in column (1), we can see that the effects of the treatments are not statistically significant. Thus, we cannot say whether the treatment effect has an influence on the students' study achievements or not. This also implies that we cannot say much about the effect of being assigned in one of the treatment or control groups, as the lack of statistical significance hinders us from saying something about the sign of the coefficients, even though the coefficient of \textit{bonus1500} is positive (implying that the treatment might increase the chance of passing all courses in first year).

In the second model, we add 3 additional control variables, namely, father's education \textit{fyeduc}, subjective self-assessment of the pass probability \textit{p0}, and high school math score \textit{math}. The results are presented in \breftable{tab_pass} in column (2). However, the significance of the treatment variables \textit{bonus500} and \textit{bonus1500} do not change. Thus, this model also implies like the one above, that the financial incentive does not influence a student's study performance in the first year significantly.

\subsection{(iii)} \label{q2_3}

In the third model, we include the variable indicating whether a student has a job (\textit{job}) and the average number of study hours (\textit{effort}). 

To comment on this approach, we do not think these two control variables are good addition to the model as it might be correlated with the treatment variables and with each other. For example, the amount of study effort one puts in might correlate with the type of reward they are assign (e.g., a higher reward means more study efforts). On the other hand, if the reward of studying is low, a student might be more incentivised to take up a part-time job, and the fact that a student has a job might lower the average number of hours they put into the study (which is measures in the variable \textit{effort}).

Nevertheless, the model still results in insignificant coefficients for the two treatment dummy variables as displayed in \breftable{tab_pass} in column (3), implying that the two added variables compared to \brefsection{q2_2} might indeed cause multicollinearity issues as the insignificance might also be attributed to imploded standard errors.

\subsection{(iv)} \label{q2_4}

For this question, we use a linear probability model similar to \brefsection{q2_3}, where we aim to explain the outcome variable with the variables \textit{bonus500}, \textit{bonus1500}, \textit{math}, \textit{fyeduc}, \textit{p0}, \textit{effort} and \textit{job} (for explanation of these variables, see \brefsection{q2_2} and \brefsection{q2_3}). Hence, we build 3 linear probability models that include the treatment variables and all exogenous variables as the predictors.

```{r}
drop_lm <- lm(dropout ~ bonus500 + bonus1500 + math + fyeduc + p0 + effort + job, data=dfData)
credsYear1_lm <- lm(stp2001 ~ bonus500 + bonus1500 + math + fyeduc + p0 + effort + job, data=dfData)
credsYear3_ln <- lm(stp2004 ~ bonus500 + bonus1500 + math + fyeduc + p0 + effort + job, data=dfData)
```

```{r, echo=TRUE, results='hide'}
stargazer::stargazer(drop_lm,credsYear1_lm,credsYear3_ln, title="Estimating dropout and credit rates with the previous model", align=TRUE, table.placement="H", label="tab_dropcred", out = "tab_dropcred.tex")
```

\input{tab_dropcred.tex}

The summary shows a clear picture. For all three dependent variables, \textit{dropout} as a measure of whether the student dropped out of the program in model (1) in \breftable{tab_dropcred}, \textit{stp2001} and \textit{stp2004} measuring the number of credits collected in the first and in the three years respectively (estimated in model (2) and (3) in \breftable{tab_dropcred}), only \textit{math} and \textit{effort} being significant, with \textit{p0} significant only for model (2). Thus good high school math score implies lower risk of dropping out and higher amount of credits collected for both first and all years. Furthermore, the amount of effort (number of hours on average) works in a similar fashion, i.e. the more the student studies, the less likely they will be to drop out and the more credits they will achieve. Interestingly, the self-assessed likelihood of success before the program also seems to impact the first year credits positively, which might mean that there is an underlying variable such as motivation connected to this. However, we can also concur that the effect of the financial incentives is not significant, as both \textit{bonus500} and \textit{bonus1500} are insignificant for all three models.

\subsection{(v)} \label{q2_5}

The minimum detectable effect of this experiment is the measure using the formula:

\begin{equation} \label{eq_mde}
\begin{aligned}
MDE = (t_{1-\alpha/2} - t_{1-q}) \sqrt{\frac{1}{p(1-p)}} \sqrt{\frac{\sigma^2}{n}}
\end{aligned}
\end{equation}

We need to calculate the MDE for both low-reward versus control group and high-reward versus control group. Therefore, our calculations follow as:

```{r}
MinDE <- function(dfData, input_model, sTreatment, dAlpha, dPower){
  num_coef <- length(input_model$coefficients)
  
  # get the number of observations
  n_obs <- nrow(dfData)
  # Observations in treated group
  n_treatment <- sum(dfData[,sTreatment])
  # Proportion of treatment observations
  proportion <- n_treatment/n_obs
  
  # T_statistics of alpha and power levels
  t_stats_alpha <- qt(1-dAlpha/2, n_obs - num_coef)
  t_power <- qt(1-dPower, n_obs - num_coef)
  
  # get variance of residuals
  dVariance <- var(input_model$residuals)
  
  # get the MDE
  MDE <- (t_stats_alpha - t_power) * sqrt(1/(proportion*(1-proportion))) * sqrt(dVariance/n_obs)
  return(MDE)
}

# Initialize desired alpha and power
dAlpha = 0.05
dPower = 0.75

# Prepare dataframe
df_low_treatment = dfData[dfData$bonus1500 != 1,]
df_high_treatment = dfData[dfData$bonus500 != 1,]

#Estimate linear model with low reward treatment and control group

Low_treatment = lm(pass ~ bonus500 + math + fyeduc + p0 + effort + job, data=df_low_treatment)

#Get MDE of low-reward versus control group
MDE_low = MinDE(df_low_treatment,Low_treatment,"bonus500",dAlpha, dPower)

#Estimate linear model with high reward treatment and control group
High_treatment = lm(pass ~ bonus1500 + math + fyeduc + p0 + effort + job, data=df_high_treatment)

#Get MDE of high-reward versus control group
MDE_high = MinDE(df_high_treatment, High_treatment,"bonus1500",dAlpha, dPower)

cat("The MDE of the low reward treatment group is: ", MDE_low, ", \n", "and the MDE of the high reward treatment group is: ", MDE_high)
```

\subsection{(vi)} \label{q2_6}

An increases in the pass rate of $10\%$ points correspond with the Minimum Detectable Effect size of $10\%$. Given this, we can calculate the minimum number of observations needed using the rewritten version of \beqref{eq_mde}:

\begin{equation} \label{eq_nmin}
\begin{aligned}
n = \biggl( \frac{t_{1-\alpha/2} - t_{1-q}}{MDE} \biggl)^2 \frac{\sigma^2}{p(1-p)}
\end{aligned}
\end{equation}

However, for this we need to make a few assumptions. Since we are looking for the minimum sample size, we do not know $n$ and the degrees of freedom to calculate the t-stats in the numerator of \beqref{eq_nmin}. Therefore, we need to assume that $n$ is large enough to approach normal distribution (asymptotics) and calculate the statistics using a standard normal distribution.

```{r}
get_n <- function(dfData, input_model, sTreatment, dAlpha, dPower, MinDE=0.1, dSigma_sq){
  # T_statistics of alpha and power levels
  t_stats_alpha <- qnorm(1-dAlpha/2, 0,dSigma_sq)
  t_power <- qnorm(1-dPower, 0, dSigma_sq)
  
  # get the number of observations
  n_obs <- nrow(dfData)
  # Observations in treated group
  n_treatment <- sum(dfData[,sTreatment])
  # Proportion of treatment observations
  proportion <- n_treatment/n_obs
  
  # get the desired sample size
  sample_size = ((t_stats_alpha-t_power)/MinDE)^2*(dSigma_sq/(proportion/(1-proportion)))
  return(round(sample_size))
}

# Initialize, set sigma and alpha fixed
dSigma_sq = 1
dAlpha= 0.5
dPower = 0.8

# required sample sizes needed in each treatment group
sample_low_required = get_n(df_low_treatment, input_model = Low_treatment,"bonus500", dAlpha = dAlpha, dPower = dPower, dSigma_sq = dSigma_sq)

sample_high_required = get_n(df_high_treatment, input_model = High_treatment,"bonus1500", dAlpha = dAlpha, dPower = dPower, dSigma_sq = dSigma_sq)

cat("The minimum sample size to detect a 10% point increase", "\n", "in the low reward treatment group is: ", sample_low_required, ", \n", "in the high reward treatment group is: ", sample_high_required, ", \n", "and the number of observations in the dataset is:", nrow(dfData))
```
From these results, we can establish that the sample size of the data is just barely achieving the minimum sample size to detect such a change in the dependent variable resulting from the treatment in the low treatment group, and in fact it is just below the minimum sample size to detect such a change in the high treatment group. Hence perhaps it would be interesting to see what would happen to the treatment coefficients if one would increase the sample size slightly.

\subsection{(vii)} \label{q2_7}

Looking at the formula for MDE in \beqref{eq_mde}, fewer students in the experiment mean higher MDE (since $n$ is in denominator). If we want to achieve the same MDE with fewer students, we need to choose the proportion of control versus treatment group such that the term $p(1-p)$ is minimized (since this term is also in the denominator). Taking the derivative of that term with respect to $p$, we find the optimal value of $p = 0.5$ where p is the proportion of treated students. To get $p=0.5$, we indeed need to increase number of students in the control group.

Do you agree? now we need to relate this with our dataset, do some count functions, then we're done!


